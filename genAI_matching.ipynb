{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35e2393d-58e5-4f00-98d5-3445e735f2e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Codes for Matching Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f1b3f-8a9d-49d0-adf7-b0ef3285952d",
   "metadata": {},
   "source": [
    "### Matching Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe78e9-5602-4efd-98c2-d7bf0f7a4d58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random\n",
    "def alg_random(giver, takers, g2t, t2g):\n",
    "    candidates = random.sample(takers, n_choice)\n",
    "    return candidates\n",
    "\n",
    "# CF: Collaborative Filtering\n",
    "def alg_CF(givers, takers, scores):\n",
    "    df = scores[scores.giver.isin(givers) & scores.taker.isin(takers)]\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(df, reader)\n",
    "    trainset = data.build_full_trainset()\n",
    "    model = SVD(n_factors=100, random_state=0)\n",
    "    model.fit(trainset)\n",
    "    def get_top_n(giver):\n",
    "        not_rated = df.loc[df['giver'] != giver, 'taker'].unique()\n",
    "        predictions = [model.predict(giver, taker) for taker in not_rated]\n",
    "        top_n_takers = sorted(predictions, key=lambda x: x.est, reverse=True)[:n_choice]\n",
    "        return [pred.iid for pred in top_n_takers]\n",
    "    cand_dict = {}\n",
    "    for giver in givers:\n",
    "        cand_dict[giver] = get_top_n(giver)\n",
    "    return cand_dict\n",
    "\n",
    "# EM: Efficiency-Maximizing\n",
    "def alg_EM(giver, takers, g2t, t2g):\n",
    "    candidates = g2t[g2t.giver == giver].sort_values('y_pred', ascending=False).taker[:n_choice]\n",
    "    return candidates\n",
    "\n",
    "# FA: Fairness-Aware\n",
    "# FA@1\n",
    "def alg_FA1(giver, takers, g2t, t2g):\n",
    "    superstar = round(len(takers)*0.01)\n",
    "    candidates = g2t[g2t.giver == giver].sort_values('y_pred', ascending=False).taker[superstar:superstar+n_choice]\n",
    "    return candidates\n",
    "# FA@2\n",
    "def alg_FA2(giver, takers, g2t, t2g):\n",
    "    superstar = round(len(takers)*0.02)\n",
    "    candidates = g2t[g2t.giver == giver].sort_values('y_pred', ascending=False).taker[superstar:superstar+n_choice]\n",
    "    return candidates\n",
    "# FA@5\n",
    "def alg_FA5(giver, takers, g2t, t2g):\n",
    "    superstar = round(len(takers)*0.05)\n",
    "    candidates = g2t[g2t.giver == giver].sort_values('y_pred', ascending=False).taker[superstar:superstar+n_choice]\n",
    "    return candidates\n",
    "# FA@10\n",
    "def alg_FA10(giver, takers, g2t, t2g):\n",
    "    superstar = round(len(takers)*0.10)\n",
    "    candidates = g2t[g2t.giver == giver].sort_values('y_pred', ascending=False).taker[superstar:superstar+n_choice]\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e358e375-5312-4e28-ac6f-df6971dff208",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c98558-ff3f-4330-adc9-007ee938b34a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_prep(df_giver, df_taker, exp_dir):\n",
    "\n",
    "    df_giver['key'] = 1\n",
    "    df_taker['key'] = 1\n",
    "\n",
    "    cross_joined = pd.merge(df_giver, df_taker, on='key').drop('key', axis=1)\n",
    "    id_y_column = cross_joined.pop('id_y')\n",
    "    cross_joined.insert(1, 'id_y', id_y_column)\n",
    "    df_giver = df_giver.drop(\"key\", axis = 1)\n",
    "    df_taker = df_taker.drop(\"key\", axis = 1)\n",
    "    col_list = cross_joined.columns.tolist()    \n",
    "    selected_columns = cross_joined.loc[:, col_list[:81] + col_list[81+512:-512] + col_list[81:81+512] + col_list[-512:]]\n",
    "\n",
    "    return selected_columns.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce6ed07-3669-48b7-a6b8-b1d2855e4e37",
   "metadata": {},
   "source": [
    "### Rating Inference with Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bec782-f89c-4bfa-90f2-2e349c84f852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rating_inference(g2t_sample, exp_dir):\n",
    "    \n",
    "    # Data\n",
    "    global x_train, y_train, x_test, y_test\n",
    "    x_train = g2t_sample.iloc[:, 2:]\n",
    "    y_train = g2t_sample.iloc[:, 1]   \n",
    "    x_test = g2t_sample.iloc[:, 2:]\n",
    "    y_test = g2t_sample.iloc[:, 1] \n",
    "    dataloaders = load_dataset(args)\n",
    "    \n",
    "    # Model Define\n",
    "    args.exp_dir = exp_dir\n",
    "    args.in_dim = x_test.shape[1]\n",
    "    \n",
    "    model = ComboNet(args)\n",
    "    model_name = model.__class__.__name__\n",
    "    model_dir = 'trained_models'\n",
    "    model = model.float()\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "    # Model Load\n",
    "    loaded_state_dict = torch.load(path.join(model_dir, args.exp_dir+'.pth'))\n",
    "    model.load_state_dict(loaded_state_dict)\n",
    "\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Rating Inference\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['test']:\n",
    "\n",
    "            profiles = data['profile']\n",
    "            profiles = profiles.to(device)\n",
    "\n",
    "            regression_output, classification_output = model(profiles)\n",
    "            probs = F.softmax(classification_output, dim=1)\n",
    "            cls = torch.from_numpy(np.array([[1.0, 2.0, 3.0, 4.0, 5.0]], dtype=float).T).to(device)\n",
    "            expectation = torch.matmul(probs, cls.float()).view(-1).view(-1, 1)\n",
    "\n",
    "            output = (2 * regression_output + expectation) / 3\n",
    "            y_pred += output.to(\"cpu\").detach().numpy().tolist()\n",
    "\n",
    "    pred_df = g2t_sample.iloc[:, :2]\n",
    "    pred_df['y_pred'] = [n[0] for n in y_pred]\n",
    "    pred_df.columns = ['giver', 'taker', 'y_pred']\n",
    "    \n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8bcfad-76f1-4b68-9590-e2a2bf7761a9",
   "metadata": {},
   "source": [
    "### Functions for Simulation without Facial Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533a44fd-f21a-4a49-877a-3e3e4a60f3d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulation(givers, takers, algorithm, g2t, t2g):\n",
    "    rec_list = []\n",
    "    if algorithm == alg_CF: \n",
    "        cf_cand_dict = alg_CF(givers, takers, scores)\n",
    "\n",
    "    for giver in givers:\n",
    "        if algorithm == alg_CF: \n",
    "            candidates = cf_cand_dict[giver]\n",
    "        else:\n",
    "            candidates = algorithm(giver, takers, g2t, t2g)\n",
    "\n",
    "        for taker in candidates:\n",
    "            g2t_score = g2t[(g2t.giver == giver) & (g2t.taker == taker)].y_pred.item()\n",
    "            g2t_like = (round(g2t_score) > like_threshold)\n",
    "            t2g_score = t2g[(t2g.giver == taker) & (t2g.taker == giver)].y_pred.item()\n",
    "            t2g_like = (round(t2g_score) > like_threshold)\n",
    "\n",
    "            rec_list.append([int(giver), int(taker), g2t_score, g2t_like, t2g_score, t2g_like])\n",
    "\n",
    "    rec_df = pd.DataFrame(rec_list, columns=['giver', 'taker', 'g2t_score', 'g2t_like', 't2g_score', 't2g_like'])        \n",
    "    rec_df['match'] = False\n",
    "    liked_df = rec_df[(rec_df['g2t_like'] == True) & (rec_df['t2g_like'] == True)]\n",
    "    top_matches = liked_df.sort_values(by=['taker', 't2g_score'],\n",
    "                                       ascending=[True, False]).groupby('taker').head(match_max)\n",
    "    rec_df.loc[top_matches.index, 'match'] = True\n",
    "    \n",
    "    return rec_df\n",
    "\n",
    "\n",
    "def gini_coefficient(counts):\n",
    "    tmp = 0\n",
    "    for i in counts:\n",
    "        for j in counts:\n",
    "            tmp += abs(i - j)\n",
    "    return (tmp/(2*len(counts)*sum(counts)))\n",
    "\n",
    "\n",
    "def sim_analysis(rec_df, gender):\n",
    "    \n",
    "    # Efficiency: Like, Match \n",
    "    like = len(rec_df[rec_df['g2t_like']])\n",
    "    match = len(rec_df[rec_df['match']])\n",
    "\n",
    "    # Fairness: Gini, High-tier rec.\n",
    "    cand_list = rec_df['taker'].values.tolist()\n",
    "    cand_cnt = Counter(cand_list)\n",
    "    if gender == 'm2f':\n",
    "        rank_df = pd.DataFrame(f_rank)\n",
    "    else:\n",
    "        rank_df = pd.DataFrame(m_rank)\n",
    "    rank_df['count'] = rank_df.index.map(cand_cnt).fillna(0)\n",
    "\n",
    "    gini_coef = gini_coefficient(rank_df['count'])\n",
    "    mid_rank = rank_df.score.median()\n",
    "    high_rate = rank_df[rank_df.score <= mid_rank]['count'].sum() / sum(cand_cnt.values())\n",
    "    low_rate = rank_df[rank_df.score > mid_rank]['count'].sum() / sum(cand_cnt.values())\n",
    "    \n",
    "    return like, match, high_rate, low_rate, gini_coef\n",
    "\n",
    "\n",
    "def lnm_count(givers, takers, g2t, t2g, gender):\n",
    "    \n",
    "    lnm_df = pd.DataFrame(columns=['algorithm', 'like', 'match', 'high_rate', 'low_rate', 'gini'])\n",
    "    alg_list = [alg_random, alg_CF, alg_EM, alg_FA1, alg_FA2, alg_FA5, alg_FA10]\n",
    "    score_mean = scores.groupby('taker')['score'].mean()\n",
    "    rec_df_list = []\n",
    "    \n",
    "    for i, algorithm in enumerate(alg_list):\n",
    "        \n",
    "        rec_df = simulation(givers, takers, algorithm, g2t, t2g)\n",
    "        like, match, high_rate, low_rate, gini_coef = sim_analysis(rec_df, gender)\n",
    "        \n",
    "        if gender == 'm2f':\n",
    "            rec_df['g_rank'] = rec_df['giver'].map(m_rank)\n",
    "            rec_df['t_rank'] = rec_df['taker'].map(f_rank)\n",
    "        else:\n",
    "            rec_df['g_rank'] = rec_df['giver'].map(f_rank)\n",
    "            rec_df['t_rank'] = rec_df['taker'].map(m_rank)\n",
    "        \n",
    "        alg_name = algorithm.__name__.split('_')[1]\n",
    "        lnm_df.loc[i] = [alg_name, like, match, high_rate, low_rate, gini_coef]\n",
    "        rec_df['alg_type'] = alg_name\n",
    "        rec_df_list.append(rec_df)\n",
    "    \n",
    "    log_df = pd.concat(rec_df_list, ignore_index=True)\n",
    "        \n",
    "    return {'result_df': lnm_df, 'rec_df': log_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9a35e6-3cc8-449d-87dc-a9abc3e706ca",
   "metadata": {},
   "source": [
    "### SHAP Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac387482-2727-4894-9992-ecbf74df9a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shap_explainer(model, dataset, args=args):\n",
    "    x = dataset.drop(['score'], axis=1)\n",
    "    y = dataset['score']\n",
    "    \n",
    "    x_np = x.values\n",
    "    x_torch = torch.from_numpy(x_np).to(device).float()\n",
    "\n",
    "    explainer = shap.DeepExplainer(model.reg_model, x_torch)\n",
    "    shap_values = explainer.shap_values(x_torch)\n",
    "    \n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350c9b7-5f21-459a-894f-a3cf6195e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_direction(gender, ids, dataset, args=args):\n",
    "    \n",
    "    # Loading Prediction Model\n",
    "    model = ComboNet(args)\n",
    "    model_name = model.__class__.__name__\n",
    "    if gender == 'm2f':\n",
    "        loaded_state_dict = torch.load('trained_models\\\\F3_M.pth')\n",
    "    else:\n",
    "        loaded_state_dict = torch.load('trained_models\\\\F3_F.pth')\n",
    "    new_state_dict = OrderedDict()\n",
    "    for n, v in loaded_state_dict.items():\n",
    "        name = n.replace('module.', '')\n",
    "        new_state_dict[name] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Individual Direction\n",
    "    shap_ind = pd.DataFrame(index=ids, columns=range(512)).fillna(0)\n",
    "    for giver, row in shap_ind.iterrows():\n",
    "        data = dataset[datset.giver == giver].drop(['giver', 'taker'], axis=1)\n",
    "        shap_val = shap_explainer(model, data, args)\n",
    "        x = data.drop(['score'], axis=1)\n",
    "        mean_adjusted = x - x.mean(axis=0)\n",
    "        diagonal = np.einsum('ij,ij->j', mean_adjusted, shap_val)\n",
    "        arr = np.array(diagonal)\n",
    "        top_feat = np.argsort(np.abs(arr))[::-1]\n",
    "        cnt = 0\n",
    "        for i in top_feat:\n",
    "            if cnt == n_edit:\n",
    "                break\n",
    "            if i >= 670:   # Checking whether it is a facial feature\n",
    "                row[i-670] += np.sign(arr[i])\n",
    "                cnt += 1    \n",
    "                \n",
    "    # Group Direction\n",
    "    top = shap_ind.sum().abs().sort_values(ascending=False).index[:n_edit]\n",
    "    shap_avg = pd.DataFrame(index=ids, columns=range(512)).fillna(0)\n",
    "    for giver, row in shap_avg.iterrows():\n",
    "        for i in top:\n",
    "            row[i] += np.sign(shap_m_ind.sum()[i])\n",
    "            \n",
    "    return shap_avg, shap_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f453b1a-5d7b-467b-8309-d6c04221c4c7",
   "metadata": {},
   "source": [
    "### Function for Simulation with Facial Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64728b3-eb1e-4af8-aba3-ff1008312b43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def edit_simulation(gender, edit_direction, edit_strength=1, edit_both=True):\n",
    "\n",
    "    if gender == 'm2f':\n",
    "        rec_df = m2f_og['rec_df'].copy()\n",
    "        giver_x = m_sample.set_index('id')\n",
    "        taker_x = f_sample.set_index('id')\n",
    "        gt_model = 'F3_M'\n",
    "        tg_model = 'F3_F'\n",
    "    else:\n",
    "        rec_df = f2m_og['rec_df'].copy()\n",
    "        giver_x = f_sample.set_index('id')\n",
    "        taker_x = m_sample.set_index('id')\n",
    "        gt_model = 'F3_F'\n",
    "        tg_model = 'F3_M'\n",
    "    \n",
    "    gt_pair = rec_df[['giver', 'taker']]\n",
    "\n",
    "    # Non-visual feature\n",
    "    gt_x = pd.merge(left=gt_pair, right=giver_x.iloc[:, :-512], how='left', left_on='giver', right_index=True)\n",
    "    gt_x = pd.merge(left=gt_x, right=taker_x.iloc[:, :-512], how='left', left_on='taker', right_index=True)\n",
    "    # GAN-enabled facial feature\n",
    "    gt_x = pd.merge(left=gt_x, right=giver_x.iloc[:, -512:], how='left', left_on='giver', right_index=True)\n",
    "    gt_x = pd.merge(left=gt_x, right=taker_x.iloc[:, -512:], how='left', left_on='taker', right_index=True)\n",
    "    gt_x = gt_x.reset_index(drop=True)\n",
    "    edit_values = (edit_strength * emb_std.values) * edit_direction.loc[gt_x['giver']].values\n",
    "    gt_x.iloc[:, -512:] += edit_values\n",
    "\n",
    "    gt_pred_result = rating_inference(gt_x, gt_model)\n",
    "\n",
    "    if edit_both:\n",
    "        tg_pair = rec_df[['taker', 'giver']]\n",
    "        # Non-visual feature\n",
    "        tg_x = pd.merge(left=tg_pair, right=taker_x.iloc[:, :-512], how='left', left_on='taker', right_index=True)\n",
    "        tg_x = pd.merge(left=tg_x, right=giver_x.iloc[:, :-512], how='left', left_on='giver', right_index=True)\n",
    "        # GAN-enabled facial feature\n",
    "        tg_x = pd.merge(left=tg_x, right=taker_x.iloc[:, -512:], how='left', left_on='taker', right_index=True)\n",
    "        tg_x = pd.merge(left=tg_x, right=giver_x.iloc[:, -512:], how='left', left_on='giver', right_index=True)\n",
    "        tg_x = tg_x.reset_index(drop=True)\n",
    "        edit_values = (edit_strength * emb_std.values) * edit_direction.loc[tg_x['taker']].values\n",
    "        tg_x.iloc[:, -512:] += edit_values\n",
    "\n",
    "        tg_pred_result = rating_inference(tg_x, tg_model)\n",
    "        \n",
    "    edit_lnm_df = pd.DataFrame(columns=['algorithm', 'like', 'match', 'high_rate', 'low_rate', 'gini'])\n",
    "    edit_rec_df_list = []\n",
    "    \n",
    "    alg_list = rec_df['alg_type'].unique()\n",
    "    for i, alg_name in enumerate(alg_list):\n",
    "        alg_index = (rec_df['alg_type'] == alg_name)\n",
    "        edit_rec_df = rec_df.loc[alg_index, :].copy()\n",
    "        edit_rec_df['g2t_score'] = gt_pred_result.iloc[(i*len(edit_rec_df)):((i+1)*len(edit_rec_df)), -1].tolist()\n",
    "        edit_rec_df['g2t_like'] = (round(edit_rec_df['g2t_score']) > like_threshold)\n",
    "        if edit_both:\n",
    "            edit_rec_df['t2g_score'] = tg_pred_result.iloc[(i*len(edit_rec_df)):((i+1)*len(edit_rec_df)), -1].tolist()\n",
    "            edit_rec_df['t2g_like'] = (round(edit_rec_df['t2g_score']) > like_threshold)\n",
    "\n",
    "        edit_rec_df['match'] = False\n",
    "        liked_df = edit_rec_df[(edit_rec_df['g2t_like'] == True) & (edit_rec_df['t2g_like'] == True)]\n",
    "        top_matches = liked_df.sort_values(by=['taker', 't2g_score'],\n",
    "                                           ascending=[True, False]).groupby('taker').head(match_max)\n",
    "        edit_rec_df.loc[top_matches.index, 'match'] = True\n",
    "\n",
    "        like, match, high_rate, low_rate, gini_coef = sim_analysis(edit_rec_df, gender)\n",
    "\n",
    "        edit_lnm_df.loc[i] = [alg_name, like, match, high_rate, low_rate, gini_coef]\n",
    "        edit_rec_df_list.append(edit_rec_df)\n",
    "\n",
    "    edit_log_df = pd.concat(edit_rec_df_list, ignore_index=True)\n",
    "        \n",
    "    return {'result_df': edit_lnm_df, 'rec_df': edit_log_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b7d2f-bdfd-4916-ab87-1617e457c5c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Matching Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab475b-9744-4ff4-8df6-c13e33c4dcff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Conditions for Matching Simulation\n",
    "n_choice = 2          # Number of counterparts recommended to each user\n",
    "like_threshold = 4    # Score criterion for deciding 'likes'  \n",
    "match_max = 10        # Maximum number of matches each user can get\n",
    "n_edit = 5            # Number of facial features modified in facial editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1111221b-324b-4e42-ade3-502d096cd535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m2f_list = []\n",
    "f2m_list = []\n",
    "m2f_rec_list = []\n",
    "f2m_rec_list = []\n",
    "\n",
    "for trial in tqdm(range(10)):\n",
    "    \n",
    "    # User Sampling\n",
    "    m_sample = m_user.sample(n=780, random_state=trial)\n",
    "    f_sample = f_user.sample(n=220, random_state=trial)\n",
    "    m_ids = list(m_sample.id)\n",
    "    f_ids = list(f_sample.id)\n",
    "    # User Ranking\n",
    "    m_score_mean = score_mean[score_mean.index.isin(m_ids)]\n",
    "    m_rank = round(m_score_mean.rank(method='min', ascending=False, pct=True).sort_values()*100, 2)\n",
    "    f_score_mean = score_mean[score_mean.index.isin(f_ids)]\n",
    "    f_rank = round(f_score_mean.rank(method='min', ascending=False, pct=True).sort_values()*100, 2)\n",
    "\n",
    "    # Data Preparation\n",
    "    m2f_f3 = data_prep(m_sample, f_sample, 'F3_M')\n",
    "    m_sample = m_sample.drop(\"key\", axis=1)\n",
    "    f_sample = f_sample.drop(\"key\", axis=1)\n",
    "    m2f_f3_pred = rating_inference(m2f_f3, 'F3_M')\n",
    "    f2m_f3 = data_prep(f_sample, m_sample, 'F3_F')\n",
    "    m_sample = m_sample.drop(\"key\", axis=1)\n",
    "    f_sample = f_sample.drop(\"key\", axis=1)\n",
    "    f2m_f3_pred = rating_inference(f2m_f3, 'F3_F')\n",
    "\n",
    "    # Simulation without Facial Editing\n",
    "    # Recommending Female to Male\n",
    "    m2f_og = lnm_count(m_ids, f_ids, m2f_f3_pred, f2m_f3_pred, 'm2f')\n",
    "    m2f_og['result_df']['edit_type'] = 'no_edit'\n",
    "    m2f_og['rec_df']['edit_type'] = 'no_edit'\n",
    "    m2f_list.append(m2f_og['result_df'])\n",
    "    m2f_rec_list.append(m2f_og['rec_df'])\n",
    "    # Recommending Male to Female\n",
    "    f2m_og = lnm_count(f_ids, m_ids, f2m_f3_pred, m2f_f3_pred, 'f2m')\n",
    "    f2m_og['result_df']['edit_type'] = 'no_edit'\n",
    "    f2m_og['rec_df']['edit_type'] = 'no_edit'\n",
    "    f2m_list.append(f2m_og['result_df'])\n",
    "    f2m_rec_list.append(f2m_og['rec_df'])\n",
    "    \n",
    "    # Exploring Preference Direction\n",
    "    shap_m_avg, shap_m_ind = explore_direction('m2f', m_ids, shap_m_f3, args)\n",
    "    shap_f_avg, shap_f_ind = explore_direction('f2m', f_ids, shap_f_f3, args)\n",
    "    avg_edit = pd.concat([shap_m_avg, shap_f_avg])\n",
    "    ind_edit = pd.concat([shap_m_ind, shap_f_ind])\n",
    "    emb_std = emb.set_index('id').std()\n",
    "    \n",
    "    # Simulation with Group Preference Editing\n",
    "    # Female is Recommended to Male\n",
    "    m2f_avg_both = edit_simulation(gender='m2f', edit_direction=avg_edit, edit_strength=1, edit_both=True)\n",
    "    m2f_avg_both['result_df']['edit_type'] = 'avg_both'\n",
    "    m2f_avg_both['rec_df']['edit_type'] = 'avg_both'\n",
    "    m2f_list.append(m2f_avg_both['result_df'])\n",
    "    m2f_rec_list.append(m2f_avg_both['rec_df'])\n",
    "    # Male is Recommended to Female\n",
    "    f2m_avg_both = edit_simulation(gender='f2m', edit_direction=avg_edit, edit_strength=1, edit_both=True)\n",
    "    f2m_avg_both['result_df']['edit_type'] = 'avg_both'\n",
    "    f2m_avg_both['rec_df']['edit_type'] = 'avg_both'\n",
    "    f2m_list.append(f2m_avg_both['result_df'])\n",
    "    f2m_rec_list.append(f2m_avg_both['rec_df'])\n",
    "    \n",
    "    # Simulation with Individual Preference Editing\n",
    "    # Female is Recommended to Male\n",
    "    m2f_ind_both = edit_simulation(gender='m2f', edit_direction=ind_edit, edit_strength=1, edit_both=True)\n",
    "    m2f_ind_both['result_df']['edit_type'] = 'ind_both'\n",
    "    m2f_ind_both['rec_df']['edit_type'] = 'ind_both'\n",
    "    m2f_list.append(m2f_ind_both['result_df'])\n",
    "    m2f_rec_list.append(m2f_ind_both['rec_df'])\n",
    "    # Male is Recommended to Female\n",
    "    f2m_ind_both = edit_simulation(gender='f2m', edit_direction=ind_edit, edit_strength=1, edit_both=True)\n",
    "    f2m_ind_both['result_df']['edit_type'] = 'ind_both'\n",
    "    f2m_ind_both['rec_df']['edit_type'] = 'ind_both'\n",
    "    f2m_list.append(f2m_ind_both['result_df'])\n",
    "    f2m_rec_list.append(f2m_ind_both['rec_df'])\n",
    "\n",
    "    # Trial Record\n",
    "    for df in m2f_list[-3:]:\n",
    "        df['trial'] = trial\n",
    "    for df in f2m_list[-3:]:\n",
    "        df['trial'] = trial\n",
    "        \n",
    "    for df in m2f_rec_list[-3:]:\n",
    "        df['trial'] = trial\n",
    "    for df in f2m_rec_list[-3:]:\n",
    "        df['trial'] = trial\n",
    "\n",
    "# Gender Record\n",
    "for df in m2f_list:\n",
    "    df['gender'] = 'm2f'\n",
    "for df in f2m_list:\n",
    "    df['gender'] = 'f2m'\n",
    "    \n",
    "for df in m2f_rec_list:\n",
    "    df['gender'] = 'm2f'\n",
    "for df in f2m_rec_list:\n",
    "    df['gender'] = 'f2m'\n",
    "        \n",
    "sim_result = pd.concat(m2f_list+f2m_list, ignore_index=True)\n",
    "sim_log = pd.concat(m2f_rec_list+f2m_rec_list, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ksj",
   "language": "python",
   "name": "ksj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
